Team Members: Addison Nugent (GitHub ID: ), Ashton Frias (GitHub ID: AshtonFrias), Jordan Locke (GitHub ID: jll19gGH), and Colin Houde (GitHub ID: ColinHoude)


Group Project Name: Recipe Website Generator


Repository Link: https://github.com/AshtonFrias/Website_Generator-COP4521-
Note: Invites have been sent to both kuhnle@cs.fsu.edu and barao@cs.fsu.edu from the GitHub ID AshtonFrias


Detailed project plan: We are developing a recipe generator that will use a website scraper to find recipes that fit the user’s entered criteria.  The criteria will include tags for cuisine (Chinese, Mexican, etc.), diet (Vegetarian, Keto, etc.), difficulty, meal type (Appetizer, Dinner, etc.), nutrition, location based and so on. The user also has the option to input specific ingredients (such as onions, broccoli, chicken, etc.) that they would like in the recipe. If the user does not enter any criteria, our generator surprises them with recipes fitting a random combination of tags. We do not have a specific website API yet in mind to use to get the recipes but the idea is that the website scraper uses the website’s search function to input the user’s criteria. The scraper would then pull the top 10 or so results and display those to the user and save them to a database. The user will be able to browse the recipes. There will also be a button for the user to “refresh” the recipes and the scraper will pull the next 10 results. 


Started development on the project: So far, we created a project using Flask and created a recipe database to serve as a demo/starting point for the generator (program is on our GitHub). In future iterations, more features will be added (such as an option to list ingredients, more tags, music, a cleaner UI, etc.) and we will implement a website scraper to build the database for us instead of us building it manually (which is what we do in the demo).


Plan for the future: The first thing we need to sort out in order to move further will be to choose a scraper API or a public database of recipes we can sort through. We have a few picked out already but will likely choose the one with the most information stored and is easiest to use. After that we will implement the search function and continue to refine based on different types of searches.