# Recipe Website Python (COP 4521 - Fall 2021)
# Latest Status Report (11/3)

**Team Members:** Addison Nugent (GitHub ID: sydsyd-nugs), Ashton Frias (GitHub ID: AshtonFrias), Jordan Locke (GitHub ID: jll19gGH), and Colin Houde (GitHub ID: ColinHoude)

**Group Project Name:** Recipe Website Generator

**Repository Link:** https://github.com/AshtonFrias/Website_Generator-COP4521-
*Note: Invites have been sent to both kuhnle@cs.fsu.edu and barao@cs.fsu.edu from the GitHub ID AshtonFrias

**Detailed project plan:** We are developing a recipe generator that will use website scrapers to find recipes that fit the user’s entered criteria.  The criteria will include tags for cuisine (Chinese, Mexican, etc.), diet (Vegetarian, Keto, etc.), difficulty, meal type (Appetizer, Dinner, etc.), nutrition, location based and so on. The user also has the option to input specific ingredients (such as onions, broccoli, chicken, etc.) that they would like in the recipe. If the user does not enter any criteria, our generator surprises them with recipes fitting a random combination of tags. We are using Beautiful Soup 4 to extract the recipe URLs from the user’s search result. To extract the information of a recipe, we are using Recipe-Scrapers. The user will be able to browse the recipes and add/remove them to/from another database or list (not sure yet how we will store that). The user will have the option to send this list via email.

**Current development on the project:** We still have the basic website we set up using Flask in the last Status Report. The user is still only able to choose from a limited number of tags and they can only select one. Once they select a tag, the Beautiful Soup 4 web scraper collects the search results from https://www.allrecipes.com/ then we use recipe-scrapers to collect the information for each recipe URL. This information is added to a database which is displayed to the user for browsing. We also added an email feature so we can send emails to the user. The feature is set up but not complete yet. As of now, you can send emails but cannot save recipes yet so the email just has a test message.

**Plan for the future:** Right now, we are scraping recipes from https://www.allrecipes.com/ but we may  switch to a different website soon that has a better search function. For example, when we search for “Italian dinner”, some Italian dinner ideas come up but there are also results for desserts, snacks, and appetizers which obviously do not match the user’s desired criteria. We also need to improve the overall UI and database presentation on our website because as of now, it is really basic and plain. We still need to add our other features too, such as the ability to search for recipes with specific ingredients, add more tags for the user to choose from/allow the user to select multiple tags, and create some sort of list function to save recipes so they can be sent via email. Finally, there is some loading time required for web scraping so we will be looking into more ways to cut that down (right now, it is about 6-10 seconds).

**Changes to the original plan:** Originally, we were going to pull the top 10 or so search results then give the user an option to refresh the page. For some reason, Beautiful Soup 4 can only pull a certain number of URLS (varies how many  but usually 20-30 URLS come back) so we are unable to continually refresh the results like we thought we could do. Instead, we will display the top 10 or so results and the user will have the option to do a new search if they want different results. We also added an email feature to the plan since the last Status Report. Besides that, the plan is still the same.

**List of Python Libraries being used:** Flask (Use: web development), Requests (Use: helps us get web addresses), Beautiful Soup 4 (Use: helps us scrape the recipe URLS from the search results), Recipe-Scrapers (Use: scrapes information about a recipe from a URL), Smtplib (Use: Allows us to send emails), Email Message (Use: Creates an email container, which makes formatting an email easier), lxml (Use: used as the Beautiful Soup parser to try to reduce loading times), and cchardet (Use: used to try to reduce loading times).
